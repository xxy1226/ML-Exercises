{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关键词：在某一个类别的文章中，出现的次数很多，但是在其他类别的文章当中出现很少\n",
    "\n",
    "方法：TfidVectorizer\n",
    "\n",
    "* TF-IDF 主要思想：如果**某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现**，则认为此词或者短语具有很好的类别区分能力，适合用来分类。\n",
    "* TF-IDF 作用：**用以评估一字词对于一个文件或一个语料库的其中一份文件的重要程度**。\n",
    "\n",
    "1. 公式\n",
    "* TF: 词频（Term Frequency）指的是某一个给定的词语在该文件中出现的频率\n",
    "* IDF: 逆向文档频率（Inverse document Frequency）是一个词语普遍重要性的度量。某一特定词语的IDF，可以**由总文件数除以包含该词语之文件的数目，再将得到的商取以10为底的对数得到**\n",
    "\n",
    "   $tfidf_{i,j} = tf_{i,j} \\times idf_{i}$\n",
    "\n",
    "   **例子**：  \n",
    "   语料库有1000篇文章  \n",
    "   有100篇文章包含“非常”  \n",
    "   有10篇文章包含“经济”  \n",
    "   现在有两篇文章：\n",
    "   * 文章A包含100个词，其中10次“经济”  \n",
    "      * tf: $10/100 = 0.1$\n",
    "      * idf: $\\lg{(1000/10)} = \\lg{100} = 2 $\n",
    "      * $tfidf = 0.1 \\times 2 = 0.2$\n",
    "   * 文章B包含100个词，其中10次“非常”\n",
    "      * tf: $10/100 = 0.1$\n",
    "      * idf: $\\lg{(1000/100)} = \\lg{10} = 1$  \n",
    "      * $tfidf = 0.1 \\times 1 = 0.1$\n",
    "\n",
    "2. API\n",
    "* sklearn.feature_extraction.text.TfidfVectorizer(stop_words = None,...)\n",
    "* 返回词的权重矩阵\n",
    "   * TfidfVectorizer.fit_transform(X)\n",
    "      * X: 文本或者包含文本字符串的可迭代对象\n",
    "      * 返回值：返回sparse矩阵\n",
    "   * TfidfVectorizer.inverse_transform(X)\n",
    "      * X: array数组 或者 sparse矩阵\n",
    "      * 返回值：转换之前数据格式\n",
    "   * TfidfVectorizer.get_feature_names()\n",
    "      * 返回值：单词列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.21320072 0.         0.         0.         0.42640143\n",
      "  0.         0.         0.         0.         0.         0.21320072\n",
      "  0.         0.21320072 0.         0.         0.         0.\n",
      "  0.21320072 0.21320072 0.         0.42640143 0.         0.21320072\n",
      "  0.         0.42640143 0.21320072 0.         0.         0.\n",
      "  0.21320072 0.21320072 0.         0.         0.21320072 0.        ]\n",
      " [0.         0.         0.2410822  0.         0.         0.\n",
      "  0.2410822  0.2410822  0.2410822  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.2410822  0.55004769\n",
      "  0.         0.         0.         0.         0.2410822  0.\n",
      "  0.         0.         0.         0.48216441 0.         0.\n",
      "  0.         0.         0.         0.2410822  0.         0.2410822 ]\n",
      " [0.15895379 0.         0.         0.63581516 0.47686137 0.\n",
      "  0.         0.         0.         0.15895379 0.15895379 0.\n",
      "  0.15895379 0.         0.15895379 0.15895379 0.         0.12088845\n",
      "  0.         0.         0.15895379 0.         0.         0.\n",
      "  0.15895379 0.         0.         0.         0.31790758 0.15895379\n",
      "  0.         0.         0.15895379 0.         0.         0.        ]]\n",
      "特征名字：\n",
      " ['不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '还是' '这样']\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def cut_word(text):\n",
    "    return \" \".join(jieba.cut(text))\n",
    "\n",
    "def tfidf_demo():\n",
    "    \"\"\"\n",
    "    用TF-IDF的方法进行文本特征抽取\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data = [\"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\",\n",
    "            \"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\",\n",
    "            \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\"]\n",
    "\n",
    "    data_new = []\n",
    "    for sent in data:\n",
    "        data_new.append(cut_word(sent))\n",
    "\n",
    "    transfer = TfidfVectorizer(stop_words=[\"一种\"])\n",
    "\n",
    "    data_final = transfer.fit_transform(data_new)\n",
    "\n",
    "    print(data_final.toarray())\n",
    "    print(\"特征名字：\\n\", transfer.get_feature_names_out())\n",
    "\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tfidf_demo()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35c4bcfff6bb594ff47b51ce5b21bcb1093d06fa0c5debe7002e3be5d50f4cc1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
