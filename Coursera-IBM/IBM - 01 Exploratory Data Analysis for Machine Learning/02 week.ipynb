{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data\n",
    "\n",
    "## CSV Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV Files\n",
    "import pandas as pd\n",
    "filepath = 'data/iris_data.csv'\n",
    "\n",
    "# # Import the data\n",
    "data = pd.read_csv(filepath)\n",
    "\n",
    "# # Values are seperated by \\t (.tsv)\n",
    "data = pd.read_csv(filepath, sep='\\t')\n",
    "\n",
    "# # space-separated file\n",
    "data = pd.read_csv(filepath, delim_whitespace=True)\n",
    "\n",
    "# # Don't use first row for column names\n",
    "data = pd.read_csv(filepath, header=None)\n",
    "\n",
    "# # Specify column names\n",
    "data = pd.read_csv(filepath, names=['Name1', 'Name2'])\n",
    "\n",
    "# # Custom missing values\n",
    "data = pd.read_csv(filepath, na_values=['NA', 99])\n",
    "\n",
    "# Print a few rows\n",
    "print(data.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON file as dataframe\n",
    "data = pd.read_json(filepath)\n",
    "\n",
    "# Write dataframe file to JSON\n",
    "data.to_json('outputfile.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Databases\n",
    "- Microsoft SQL Server\n",
    "- Postgres\n",
    "- MySQL\n",
    "- AWS Redshift\n",
    "- Oracle DB\n",
    "- Db2 Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sq3\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize path to SQLite database\n",
    "path = 'data/classic_rock.db'\n",
    "\n",
    "# Create connection SQL database\n",
    "con = sq3.Connection(path)\n",
    "\n",
    "# Write query\n",
    "query = ''' SELECT * FROM rock_songs;\n",
    "'''\n",
    "\n",
    "# Execute query\n",
    "data = pd.read_sql(query, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoSQL Database\n",
    "- Document databases: **mongoDB, couchDB**\n",
    "- Key-value stores: **Riak, Voldemort, Redis**\n",
    "- Graph databases: **Neo4j, HyperGraph**\n",
    "- Wide-column stores: **Cassandra, HBase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymongo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\Andrew\\文档\\Python\\ML\\Coursera-IBM\\IBM - 01 Exploratory Data Analysis for Machine Learning\\02 week.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Andrew/%E6%96%87%E6%A1%A3/Python/ML/Coursera-IBM/IBM%20-%2001%20Exploratory%20Data%20Analysis%20for%20Machine%20Learning/02%20week.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# SQL Data Imports\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/Andrew/%E6%96%87%E6%A1%A3/Python/ML/Coursera-IBM/IBM%20-%2001%20Exploratory%20Data%20Analysis%20for%20Machine%20Learning/02%20week.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpymongo\u001b[39;00m \u001b[39mimport\u001b[39;00m MongoClient\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Andrew/%E6%96%87%E6%A1%A3/Python/ML/Coursera-IBM/IBM%20-%2001%20Exploratory%20Data%20Analysis%20for%20Machine%20Learning/02%20week.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Create a Mongo connection\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Andrew/%E6%96%87%E6%A1%A3/Python/ML/Coursera-IBM/IBM%20-%2001%20Exploratory%20Data%20Analysis%20for%20Machine%20Learning/02%20week.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m con \u001b[39m=\u001b[39m MongoClient()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymongo'"
     ]
    }
   ],
   "source": [
    "# SQL Data Imports\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Create a Mongo connection\n",
    "con = MongoClient()\n",
    "\n",
    "# Choose database (con.list_database_names()) will display available databases)\n",
    "db = con.database_name\n",
    "\n",
    "# Create a cursor object using a query\n",
    "cursor = db.collection_name.find(query)\n",
    "\n",
    "# Expand cursor and construct DataFrame\n",
    "df = pd.DataFrame(list(cursor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APIs and Cloud Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UCI Cars data set - url location\n",
    "data_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data'\n",
    "\n",
    "# Read data into Pandas\n",
    "df = pd.read_csv(data_url, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "*   Create a variable, `path`, containing the path to the `baseball.db` contained in `resources/`\n",
    "*   Create a connection, `con`, that is connected to database at `path`\n",
    "*   Create a variable, `query`, containing a SQL query which reads in all data from the `allstarfull` table\n",
    "*   Create a variable, `observations`, by using pandas' [read_sql](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01)\n",
    "\n",
    "### Optional\n",
    "\n",
    "*   Create a variable, `tables`, which reads in all data from the table `sqlite_master`\n",
    "*   Pretend that you were interesting in creating a new baseball hall of fame. Join and analyze the tables to evaluate the top 3 all time best baseball players.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习1\n",
    "1. Which statement about the Pandas read_csv function is TRUE? 1 分  \n",
    "* It allows only one argument: the name of the file. \n",
    "* **It can read both tab-delimited and space-delimited data.**\n",
    "* It can only read comma-delimited data.\n",
    "* It reads data into a 2-dimensional NumPy array.  \n",
    "2. Which of the following is a reason to use JavaScript Object Notation (JSON) files for storing data? 1 分\n",
    "* Because the data is stored in a matrix format.\n",
    "* Because they can store NA values.\n",
    "* Because they can store NULL values.\n",
    "* **Because they are cross-platform compatible.**\n",
    "3. The data below appears in 'data.txt', and Pandas has been imported. Which Python command will read it correctly into a Pandas DataFrame? 1 分\n",
    "\n",
    "63.03 22.55 39.61 40.48 98.67 -0.25 AB  \n",
    "39.06 10.06 25.02 29 114.41 4.56 AB  \n",
    "68.83 22.22 50.09 46.61 105.99 -3.53 AB \n",
    "* pandas.read_csv('data.txt')\n",
    "* **pandas.read_csv('data.txt', header=None, sep=' ')**\n",
    "* pandas.read_csv('data.txt', delim_whitespace=True)\n",
    "* andas.read_csv('data.txt', header=0, delim_whitespace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCleaning\n",
    "## DataCleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is Data Cleaning so Important?\n",
    "* **Observations:** An instance of the data (usually a point or row in a database)\n",
    "* **Labels:** Output variable(s) being predicted\n",
    "* **Algorithms:** Computer programs that estimate models based on available data\n",
    "* **Features:** Information we have for each observation (variables)\n",
    "* **Model:** Hypothesized relationship between observations and data\n",
    "\n",
    "#### Main problems\n",
    "* **Lack of data**\n",
    "* **Too much data**\n",
    "* **Bad data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Can Data be Messy?\n",
    "* Duplicate or unnecessary data\n",
    "* Inconsistent text and typos\n",
    "* Missing data\n",
    "* Outliers\n",
    "* Data sourcing issues:\n",
    "  * Multiple systems\n",
    "  * Different database types\n",
    "  * On premises, in cloud\n",
    "* ... and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policies for Missing Data\n",
    "* **Remove** the data: remove the row(s) entirely\n",
    "* **Impute** the data: replace with substituted values. Fill in the missing data with the most common value, the average value, etc.\n",
    "* **Mask** the data: create a category for missing values\n",
    "\n",
    "### Outliers\n",
    "\n",
    "### How to Find Outliers?\n",
    "* Plots\n",
    "* Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculate the interquartile range\n",
    "q25, q50, q75 = np.percentile(data, [25, 50, 75])\n",
    "iqr = q75 - q25\n",
    "\n",
    "# calculate the min / max limits to be considered an outlier\n",
    "min = q25 - 1.5 * (iqr)\n",
    "max = q75 + 1.5 * (iqr)\n",
    "\n",
    "print(min, q25, q50, q75, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the points\n",
    "[x for x in data['Unemployment'] if x > max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Outliers: Residuals\n",
    "\n",
    "**Residuals** (differences between actual and predicted values of the outcome variable) represent model failure\n",
    "\n",
    "Approaches to calculating residuals:\n",
    "* **Standardized:** residual divided by standard error\n",
    "* **Deleted:** residual from fitting model on all data excluding current ovservation\n",
    "* **Studentized:** Deleted residuals divided by residual standard error (based on all data, or all data excluding current observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policies for Outliers\n",
    "* **Remove** them\n",
    "* **Asign** the mean or median value\n",
    "* **Transform** the variable\n",
    "* **Predict** the want the value should be:\n",
    "  * Using 'similar' observations to predict likely values\n",
    "  * Using regression\n",
    "* **Keep them**, but focus on models that are resistant to outliers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
